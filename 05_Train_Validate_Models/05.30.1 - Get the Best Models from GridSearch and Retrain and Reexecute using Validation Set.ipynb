{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "#needed to import utils.py\n",
    "sys.path.append('../') \n",
    "\n",
    "import utils\n",
    "import utils_preprocessing\n",
    "import utils_exec_models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# Surpress warnings:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "%matplotlib inline  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and save the 10 best performances obtained by GridSearch grouping by ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "SVM - SVC\n",
      "---------\n",
      "   > SINGLE-MODEL (25 best)\n",
      "25 samples were saved\n",
      "   > ENSEMBLE-IMBALANCE (25 best)\n",
      "25 samples were saved\n",
      "--------------------------\n",
      "Naïve Bayes - ComplementNB\n",
      "--------------------------\n",
      "   > SINGLE-MODEL (25 best)\n",
      "19 samples were saved\n",
      "   > ENSEMBLE-IMBALANCE (25 best)\n",
      "25 samples were saved\n",
      "-------------------------------\n",
      "Neural Networks - MLPClassifier\n",
      "-------------------------------\n",
      "   > SINGLE-MODEL (25 best)\n",
      "25 samples were saved\n",
      "   > ENSEMBLE-IMBALANCE (25 best)\n",
      "25 samples were saved\n",
      "--------------------------------------\n",
      "Decision Tree - DecisionTreeClassifier\n",
      "--------------------------------------\n",
      "   > SINGLE-MODEL (25 best)\n",
      "25 samples were saved\n",
      "   > ENSEMBLE-IMBALANCE (25 best)\n",
      "0 samples were saved\n",
      "-----------------\n",
      "k-NN - GaussianNB\n",
      "-----------------\n",
      "   > SINGLE-MODEL (25 best)\n",
      "25 samples were saved\n",
      "   > ENSEMBLE-IMBALANCE (25 best)\n",
      "25 samples were saved\n",
      "-----------------------------------------\n",
      "Random Forest - RadiusNeighborsClassifier\n",
      "-----------------------------------------\n",
      "   > SINGLE-MODEL (25 best)\n",
      "25 samples were saved\n",
      "   > ENSEMBLE-IMBALANCE (25 best)\n",
      "25 samples were saved\n"
     ]
    }
   ],
   "source": [
    "#read SINGLE-MODEL results\n",
    "csv_file = 'exec_results/results_Single_Model.csv'\n",
    "df_single_model = utils.read_csv(csv_file)\n",
    "# display(df_single_model.head(3))\n",
    "\n",
    "#read ENSEMBLE-IMBALANCE results\n",
    "csv_file = 'exec_results/results_Ensemble_Imbalance.csv'\n",
    "df_ens_imb = utils.read_csv(csv_file)\n",
    "# display(df_ens_imb.head(3))\n",
    "\n",
    "\n",
    "# get each algorithm analyzed\n",
    "algorithms = list(df_single_model.Model.unique())\n",
    "model_classes = list(df_single_model.Classifier.unique())\n",
    "# print(model_classes)\n",
    "# print(algorithms)\n",
    "\n",
    "dir_dest = os.path.abspath('exec_results/')\n",
    "\n",
    "# store all best models Object for both scenarios\n",
    "best_models = list()\n",
    "\n",
    "n_to_save = 25\n",
    "\n",
    "for algorithm, model_class in zip(algorithms, model_classes):\n",
    "    utils.print_string_with_separators(f'{algorithm} - {model_class}')\n",
    "    \n",
    "    # ==============================================================     \n",
    "    # get the \"n\" best performances for the SINGLE-MODEL scenario\n",
    "    # ==============================================================     \n",
    "    print(f'   > SINGLE-MODEL ({n_to_save} best)')\n",
    "    df_best_single_model = df_single_model.loc[(\n",
    "          (df_single_model.Model == algorithm) \n",
    "    )].copy()\n",
    "\n",
    "    \n",
    "    # get and save the 5 best results for the algorithm    \n",
    "    df_best_single_model = df_best_single_model.head(n_to_save)\n",
    "#     display(df_best_single_model)\n",
    "    csv_file = f'{dir_dest}/best_performances_{algorithm}_in_SINGLE_MODEL.csv'\n",
    "    csv_file = csv_file.replace(' ', '_')\n",
    "    utils.save_to_csv(df=df_best_single_model, csv_file=csv_file)\n",
    "\n",
    "    # Get the best models and create instances using their hyperparameters    \n",
    "    for model in utils_exec_models.get_models_object_from_results(df_best_single_model):\n",
    "#         model['csv_file'] = csv_file\n",
    "        best_models.append(model)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ==============================================================     \n",
    "    # get the \"n\" best performances for the ENSEMBLE-IMBALANCE scenario\n",
    "    # ==============================================================     \n",
    "    print(f'   > ENSEMBLE-IMBALANCE ({n_to_save} best)')\n",
    "    df_best_ens_imb = df_ens_imb.loc[(\n",
    "          (df_ens_imb.Estimator_Desc == algorithm) \n",
    "    )].copy()\n",
    "\n",
    "    \n",
    "    # get and save the 5 best results for the algorithm    \n",
    "    df_best_ens_imb = df_best_ens_imb.head(n_to_save)\n",
    "#     display(df_best_ens_imb)\n",
    "    csv_file = f'{dir_dest}/best_performances_{algorithm}_in_ENSEMBLE_IMBALANCE.csv'\n",
    "    csv_file = csv_file.replace(' ', '_')\n",
    "    utils.save_to_csv(df=df_best_ens_imb, csv_file=csv_file)\n",
    "    \n",
    "    # Get the best models and create instances using their hyperparameters    \n",
    "    for model in utils_exec_models.get_models_object_from_results(df_best_ens_imb):\n",
    "#         model['csv_file'] = csv_file\n",
    "        best_models.append(model)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Reexecute each best model as following:\n",
    "\n",
    " - ### Retrain the model using the full $Training$ set\n",
    " - ### Validate the model using the $Validation$ set \n",
    " - ### Save the $Validation$ $performances$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading results saved previously...\n",
      "  1 was already executed\n",
      "  2 was already executed\n",
      "  3 was already executed\n",
      "  4 was already executed\n",
      "  5 was already executed\n",
      "  6 was already executed\n",
      "  7 was already executed\n",
      "  8 was already executed\n",
      "  9 was already executed\n",
      " 10 was already executed\n",
      " 11 was already executed\n",
      " 12 was already executed\n",
      " 13 was already executed\n",
      " 14 was already executed\n",
      " 15 was already executed\n",
      " 16 was already executed\n",
      " 17 was already executed\n",
      " 18 was already executed\n",
      " 19 was already executed\n",
      " 20 was already executed\n",
      " 21 was already executed\n",
      " 22 was already executed\n",
      " 23 was already executed\n",
      " 24 was already executed\n",
      " 25 was already executed\n",
      " 26 was already executed\n",
      " 27 was already executed\n",
      " 28 was already executed\n",
      " 29 was already executed\n",
      " 30 was already executed\n",
      " 31 was already executed\n",
      " 32 was already executed\n",
      " 33 was already executed\n",
      " 34 was already executed\n",
      " 35 was already executed\n",
      " 36 was already executed\n",
      " 37 was already executed\n",
      " 38 was already executed\n",
      " 39 was already executed\n",
      " 40 was already executed\n",
      " 41 was already executed\n",
      " 42 was already executed\n",
      " 43 was already executed\n",
      " 44 was already executed\n",
      " 45 was already executed\n",
      " 46 was already executed\n",
      " 47 was already executed\n",
      " 48 was already executed\n",
      " 49 was already executed\n",
      " 50 was already executed\n",
      " 51 was already executed\n",
      " 52 was already executed\n",
      " 53 was already executed\n",
      " 54 was already executed\n",
      " 55 was already executed\n",
      " 56 was already executed\n",
      " 57 was already executed\n",
      " 58 was already executed\n",
      " 59 was already executed\n",
      " 60 was already executed\n",
      " 61 was already executed\n",
      " 62 was already executed\n",
      " 63 was already executed\n",
      " 64 was already executed\n",
      " 65 was already executed\n",
      " 66 was already executed\n",
      " 67 was already executed\n",
      " 68 was already executed\n",
      " 69 was already executed\n",
      " 70 was already executed\n",
      " 71 was already executed\n",
      " 72 was already executed\n",
      " 73 was already executed\n",
      " 74 was already executed\n",
      " 75 was already executed\n",
      " 76 was already executed\n",
      " 77 was already executed\n",
      " 78 was already executed\n",
      " 79 was already executed\n",
      " 80 was already executed\n",
      " 81 was already executed\n",
      " 82 was already executed\n",
      " 83 was already executed\n",
      " 84 was already executed\n",
      " 85 was already executed\n",
      " 86 was already executed\n",
      " 87 was already executed\n",
      " 88 was already executed\n",
      " 89 was already executed\n",
      " 90 was already executed\n",
      " 91 was already executed\n",
      " 92 was already executed\n",
      " 93 was already executed\n",
      " 94 was already executed\n",
      " 95 was already executed\n",
      " 96 was already executed\n",
      " 97 was already executed\n",
      " 98 was already executed\n",
      " 99 was already executed\n",
      "100 was already executed\n",
      "101 was already executed\n",
      "102 was already executed\n",
      "103 was already executed\n",
      "104 was already executed\n",
      "105 was already executed\n",
      "106 was already executed\n",
      "107 was already executed\n",
      "108 was already executed\n",
      "109 was already executed\n",
      "110 was already executed\n",
      "111 was already executed\n",
      "112 was already executed\n",
      "113 was already executed\n",
      "114 was already executed\n",
      "115 was already executed\n",
      "116 was already executed\n",
      "117 was already executed\n",
      "118 was already executed\n",
      "119 was already executed\n",
      "120 was already executed\n",
      "121 was already executed\n",
      "122 was already executed\n",
      "123 was already executed\n",
      "124 was already executed\n",
      "125 was already executed\n",
      "126 was already executed\n",
      "127 was already executed\n",
      "128 was already executed\n",
      "129 was already executed\n",
      "130 was already executed\n",
      "131 was already executed\n",
      "132 was already executed\n",
      "133 was already executed\n",
      "134 was already executed\n",
      "135 was already executed\n",
      "136 was already executed\n",
      "137 was already executed\n",
      "138 was already executed\n",
      "139 was already executed\n",
      "140 was already executed\n",
      "141 was already executed\n",
      "142 was already executed\n",
      "143 was already executed\n",
      "144 was already executed\n",
      "145 was already executed\n",
      "146 was already executed\n",
      "147 was already executed\n",
      "148 was already executed\n",
      "149 was already executed\n",
      "150 was already executed\n",
      "151 was already executed\n",
      "152 was already executed\n",
      "153 was already executed\n",
      "154 was already executed\n",
      "155 was already executed\n",
      "156 was already executed\n",
      "157 was already executed\n",
      "158 was already executed\n",
      "159 was already executed\n",
      "160 was already executed\n",
      "161 was already executed\n",
      "162 was already executed\n",
      "163 was already executed\n",
      "164 was already executed\n",
      "165 was already executed\n",
      "166 was already executed\n",
      "167 was already executed\n",
      "168 was already executed\n",
      "169 was already executed\n",
      "170 was already executed\n",
      "171 was already executed\n",
      "172 was already executed\n",
      "173 was already executed\n",
      "174 was already executed\n",
      "175 was already executed\n",
      "176 was already executed\n",
      "177 was already executed\n",
      "178 was already executed\n",
      "179 was already executed\n",
      "180 was already executed\n",
      "181 was already executed\n",
      "182 was already executed\n",
      "183 was already executed\n",
      "184 was already executed\n",
      "185 was already executed\n",
      "186 was already executed\n",
      "187 was already executed\n",
      "188 was already executed\n",
      "189 was already executed\n",
      "190 was already executed\n",
      "191 was already executed\n",
      "192 was already executed\n",
      "193 was already executed\n",
      "194 was already executed\n",
      "195 was already executed\n",
      "196 was already executed\n",
      "197 was already executed\n",
      "198 was already executed\n",
      "199 was already executed\n",
      "200 was already executed\n",
      "201 was already executed\n",
      "202 was already executed\n",
      "203 was already executed\n",
      "204 was already executed\n",
      "205 was already executed\n",
      "206 was already executed\n",
      "207 was already executed\n",
      "208 was already executed\n",
      "209 was already executed\n",
      "210 was already executed\n",
      "211 was already executed\n",
      "212 was already executed\n",
      "213 was already executed\n",
      "214 was already executed\n",
      "215 was already executed\n",
      "216 was already executed\n",
      "217 was already executed\n",
      "218 was already executed\n",
      "219 was already executed\n",
      "220 was already executed\n",
      "221 was already executed\n",
      "222 was already executed\n",
      "223 was already executed\n",
      "224 was already executed\n",
      "225 was already executed\n",
      "226 was already executed\n",
      "227 was already executed\n",
      "228 was already executed\n",
      "229 was already executed\n",
      "230 was already executed\n",
      "231 was already executed\n",
      "232 was already executed\n",
      "233 was already executed\n",
      "234 was already executed\n",
      "235 was already executed\n",
      "236 was already executed\n",
      "237 was already executed\n",
      "238 was already executed\n",
      "239 was already executed\n",
      "240 was already executed\n",
      "241 was already executed\n",
      "242 was already executed\n",
      "243 was already executed\n",
      "244 was already executed\n",
      "245/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "246/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "247/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "248/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "249/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "250/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "251/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "252/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "253/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "254/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "255/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "256/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "257/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "258/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "259/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "260/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "261/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "262/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "263/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "264/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "265/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "266/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "267/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "268/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "269/269: Executing Balanced-Bagging(RF) in \"Ensemble-Imbalance\" scenario\n",
      "269 samples were saved\n",
      "CPU times: user 5min 40s, sys: 7.47 s, total: 5min 47s\n",
      "Wall time: 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "csv_validation_performance = os.path.abspath('exec_results/validation_results.csv')\n",
    "\n",
    "\n",
    "\n",
    "# verify if already exists an CSV with the results\n",
    "overwrite_results_saved_previously = False\n",
    "\n",
    "if os.path.exists(csv_validation_performance) and overwrite_results_saved_previously==False:\n",
    "    print('Reading results saved previously...')\n",
    "    df_validation_performance = utils.read_csv(csv_file=csv_validation_performance)\n",
    "else:\n",
    "    df_validation_performance = None\n",
    "\n",
    "\n",
    "# Get the scaled Training and Validation subsets¶\n",
    "X_train, y_train, X_valid, y_valid = utils.get_train_and_validation_data(scaled=True)\n",
    "\n",
    "y_train = y_train[utils.CLASS_COLUMN].ravel()\n",
    "y_valid = y_valid[utils.CLASS_COLUMN].ravel()\n",
    "\n",
    "\n",
    "i = 0\n",
    "tot = len(best_models)\n",
    "\n",
    "\n",
    "\n",
    "## For each best model:\n",
    "#    1. Retrain using using the Training data\n",
    "#    2. Validate using the Validation data\n",
    "\n",
    "\n",
    "for model_info in best_models:\n",
    "\n",
    "    \n",
    "    try:    \n",
    "\n",
    "        # get the classifier name (without the parameters)\n",
    "        model_instance = model_info['model_instance']\n",
    "        scenario = model_info['Scenario']\n",
    "        model = model_info['Model']\n",
    "        model_params = model_info['Hyperparams']\n",
    "        estimator = model_info['Estimator']\n",
    "        estimator_params = model_info['Estimator_Hyperparams']\n",
    "\n",
    "        model_str = f'{model}' + ('' if scenario=='Single-Model' else f'({estimator})')\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "        # check if model was already executed\n",
    "        if df_validation_performance is not None:\n",
    "            if scenario == 'Single-Model':\n",
    "                df_executed = df_validation_performance.loc[\n",
    "                    (df_validation_performance.Scenario == scenario)\n",
    "                   &(df_validation_performance.Model == model) \n",
    "                   &(df_validation_performance.Model_Hyperparams == model_params) \n",
    "                   &(df_validation_performance.Estimator.isnull()) \n",
    "                   &(df_validation_performance.Estimator_Hyperparams.isnull()) \n",
    "                ].copy()\n",
    "            else:\n",
    "                df_executed = df_validation_performance.loc[\n",
    "                    (df_validation_performance.Scenario == scenario)\n",
    "                   &(df_validation_performance.Model == model) \n",
    "                   &(df_validation_performance.Model_Hyperparams == model_params) \n",
    "                   &(df_validation_performance.Estimator == estimator) \n",
    "                   &(df_validation_performance.Estimator_Hyperparams == estimator_params) \n",
    "                ].copy()\n",
    "            \n",
    "            if df_executed.shape[0] > 0:\n",
    "                print(f'{i:>3} was already executed: {model_str} in \"{scenario}\" scenario')\n",
    "                continue\n",
    "\n",
    "        \n",
    "        print(f'{i:>3}/{tot}: Executing {model_str} in \"{scenario}\" scenario',)\n",
    "\n",
    "        # Retrain using the full traning set\n",
    "        model_instance.fit(X_train, y_train)\n",
    "\n",
    "        #predict using the Validation set\n",
    "        y_pred = model_instance.predict(X_valid)\n",
    "\n",
    "        #get Validation performance\n",
    "        bal_acc, sens, spec, auc, acc, prec, f1 = utils_exec_models.get_scores_from_predict(\n",
    "            y_validation=y_valid, \n",
    "            y_pred=y_pred, \n",
    "        )\n",
    "\n",
    "        # Store the Validation and Training performances\n",
    "        performance_to_save = {\n",
    "            'Scenario': scenario,\n",
    "            'Model': model,\n",
    "            'Estimator': estimator,\n",
    "            # Validation performance\n",
    "            'Valid_BalAcc': bal_acc,\n",
    "            'Valid_Sens'  : sens,\n",
    "            'Valid_Spec'  : spec,\n",
    "            'Valid_f1'    : f1,\n",
    "            'Valid_AUC'   : auc,\n",
    "            'Valid_Acc'   : acc,\n",
    "            'Valid_Prec'  : prec,\n",
    "            #\n",
    "            'Model_Hyperparams': model_params,\n",
    "            'Estimator_Hyperparams': estimator_params,\n",
    "        }\n",
    "\n",
    "        # create a dataFrame to store the performances\n",
    "        df_aux = pd.DataFrame([performance_to_save])\n",
    "\n",
    "        if df_validation_performance is None:\n",
    "            df_validation_performance = df_aux\n",
    "        else:\n",
    "            df_validation_performance = pd.concat(\n",
    "                [df_validation_performance, df_aux],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "\n",
    "    except Exception as ex:\n",
    "        print('Instance')\n",
    "        print(model_instance)\n",
    "        print('INFO')\n",
    "        print(model_info)\n",
    "        print('ERROR')\n",
    "        raise Exception(ex)\n",
    "       \n",
    "\n",
    "\n",
    "# sort the validation performances\n",
    "df_validation_performance = utils_exec_models.sort_performances_results(\n",
    "    df=df_validation_performance,\n",
    "    cols_order_to_sort=[\n",
    "        'Scenario', \n",
    "#         'Model', \n",
    "#         'Estimator', \n",
    "        'Valid_BalAcc', \n",
    "        'Valid_Sens', \n",
    "        'Valid_Spec'],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# save validation performances\n",
    "utils.save_to_csv(\n",
    "    df=df_validation_performance, \n",
    "    csv_file=csv_validation_performance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# OTHERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[utils.CLASS_COLUMN].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
